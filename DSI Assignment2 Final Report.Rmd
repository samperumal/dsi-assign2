---
title: "DSI Assignment 2 Final Report"
authors: "Merve Aydin Chester AYDMER001",
         "Audrey Pentz, PNTAUD001",
         "Sam Perumal PRMSAM001",
         "Vanessa Saker, SKRVAN001"
date: "September 20, 2018"
output: html_document
---


```{r setup, include=FALSE}

##---------------------------------##
## ADD ANY LIBRARIES USED HERE
##---------------------------------##

knitr::opts_chunk$set(
  echo = TRUE,
  library(tidyverse),
  library(tidytext),
  library(stringr),
  library(lubridate),
  library(knitr),
  library(wordcloud),
  library(wordcloud2),    # wordcloud
  library(kableExtra),    # tables
  library(formattable)    # coloured cell in a table
)

##---------------------------------##
## DATA LOADED SO NO NEED TO RELOAD
##---------------------------------##

load("../input_data.RData")
load("../sentence_data.RData")

```


# **Description of the Problem**

We were given 30 State of the Nation (SONA) speeches from 1994 to 2018 to analyse. The specific objectives are to: 
1. Infer sentiment and changes in sentiment over time  
2. Describe the topics that emerge  
3. Predict the President from a given sentence of text  
4. Evaluate out of sample performance of the predictions  


# **Approach**  

We collaborated using the following GitHub location: https://github.com/samperumal/dsi-assign2. 

We initially split the work as follows and each of us created a folder with our names to push our work to for others to view:  
- Neural Net - Sam and Merve
- Bag of Words - Merve
- Topic Modelling - Vanessa
- Sentiment Analysis - Audrey

We presented our work to each other and made suggestions for improvement. The initial results from the Neural Net gave a 65% accuracy on the validation set and we wanted to feed the results of the Topic Modelling and Sentiment Analysis into the Neural Net to see if it would improve results so we needed to understand from each other what the output of these 2 methods was and the input required by the neural net to get the data into a useable format which took some discussion and a few iterations.

Given the low accuracy of the neural net (NN), we also tried a Convolutional Neural Net (CNN). Sam got the initial model working. Merve made improvements. Vanessa tuned the hyperparamters.
...need more here...

The cnn did not provide much improvement over the NN so we also tried a Recurrent Neural Net (RNN) which takes in sequences of data so the order of the words is also taken into account in the model.
...need more here...

Initially we each performed our own import of the data, splitting out the year and president and tokenisation but we realised there was duplication of effort here and different naming conventions which made it difficult to collaborate and use each other's output. In addition, Sam noticed that some of the data was not being read in because of special characters and sentences were not being tokenised correctly for various reasons so he became responsible for performing the data clean up (preprocessing) and outputting a .RData file that we could all then use to rerun our work. This is explained in more detail below and at a high level includes:   
- removing special characters such as slashes, currency symbols, currency values and numbers  
- changing bullet points, colons, semi-colons and ellipsis to full stops  
- changing the word after a full stop to sentence case  
- removing multiple spaces and multiple full stops  

Sam also assigned sentence id's using hashing and split the data into training and validation sets so that there would be consistency across what we were working on so that we could use each others work and compare results more easily.

```{r preprocessing}

# sam

```

Before diving into any analysis, we felt it is important to do an Exploratory Data Analysis (EDA) to get a sense of the high level overview of the dataset. This was done by Audrey.

### **Overview of the dataset**  

Each president has made a certain number of SONA speeches, depending on their term in office and whether there was 1 speech that year or 2 in the year of an election (pre and post election). Let's understand the number of words used by each President and how this varies across each SONA speech.  

#### **Average number of words used per President**  

We need to create a metric called "avg_words" which is simply the total number of words across all SONA speeches made by a particular president, divided by the total number of SONA speeches that president made.  

```{r descPres}

# sentence tokenization
tidy_sona_sentences <- input_data$sentences

# word tokenization
tidy_sona_words <- input_data$words %>% 
  filter(!word %in% stop_words$word, str_detect(word, "[a-z]"))  # remove stop words

# bigram tokenization
bigrams <- tidy_sona_sentences %>% 
  unnest_tokens(bigram, sentence, token = "ngrams", n = 2)
# separate the bigrams 
bigrams_separated <- bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")
# remove stop words
bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)
# join up the bigrams again
tidy_sona_bigrams <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")

# speeches
speech_count <- tidy_sona_words %>%
  group_by(year, president) %>%
  count() %>% 
  group_by(president) %>% 
  summarise(num_speeches = n())

# avg words per president
avg_word_count <- tidy_sona_words %>%
  group_by(president) %>% 
  summarise(num_words = n()) %>% 
  left_join(speech_count) %>% 
  mutate(avg_words = round((num_words/num_speeches),0)) %>% 
  arrange(desc(avg_words))

# plot avg words per president
avg_word_count %>%
  ungroup(avg_words, president) %>%
  mutate(avg_words = color_bar("lightblue")(avg_words)) %>%
  kable("html", escape = FALSE, align = "l", caption = "Average number of words used per President") %>%
  kable_styling(bootstrap_options = 
                  c("striped", "condensed", "bordered"), 
                  full_width = FALSE)

```
  
##### **Insights:**   

On average, Mbeki used the most words in his SONA speeches, followed by Motlanthe and de Klerk used the least. Mandela and Zuma are ranked in the middle of their peers. The current president (Ramaphosa) used fewer words than all of his post 1994 peers.  



#### **Number of words used per SONA**  

```{r descSONA}

# per SONA
word_count <- tidy_sona_words %>%
  group_by(president, year, election) %>%
  summarise(num_words = n()) %>%
  arrange(desc(num_words)) 

# plot words per SONA
word_count %>%
  ggplot(aes(x = as.numeric(year), y = num_words, colour = president)) +
  geom_point() + 
  geom_smooth(method = "loess", aes(colour = president))

```
  
##### **Insights:**   

Of the 3 presidents that have made more than 1 SONA speech, Mbeki used more words on average than both Mandela and Zuma and the variance in the number of words used per SONA speech is also higher for Mbeki. In 2004, which was an election year, the average number of words Mbeki used was lower in both his pre- and post-election speeches. Towards the end of his term, his average number of words also dropped off. The data suggests that perhaps Mbeki's average number of words is correlated with his confidence in being re-elected President.  



### **What are the common words used across all SONA speeches?**  

```{r}

# word cloud for words
word_count <- tidy_sona_words %>%
  count(word, sort = TRUE)

wordcloud2(word_count[1:300, ], size = .6, color='random-dark')

```
  
##### **Insights:**   

....  


### **What are the common bigrams used across all SONA speeches?**  

```{r}

# word cloud for bigrams
bigram_count <- tidy_sona_bigrams %>%
  count(bigram, sort = TRUE)

wordcloud2(bigram_count[1:300, ], size = .8, color='random-dark')

```
  
##### **Insights:**   

....



### **Lexical Diversity per President**  

Lexical diversity refers to the number of unique words used in each SONA.

```{r diversity}

# word tokenization
diversity_per_year <- input_data$words %>%   # don't remove stop words this time
  group_by(president, year) %>% 
  summarise(diversity = n_distinct(word)) %>% 
  arrange(desc(diversity))

diversity_per_year %>%
  ggplot(aes(x = as.numeric(year), y = diversity, colour = president)) +
  geom_point(color = "steelblue",
               alpha = .7,               # transparency
               size = 3,                 # point size
               position = "jitter") +    # point overlap
  geom_smooth(method = "loess", aes(colour = president)) +
  ggtitle("Lexical Diversity per President") +
  xlab("year") +
  ylab("")

```
  
##### **Insights:**   

The number of unique words per SONA ranges from about 700 with de Klerk in 1994 to over 2500 with Mandela in his post election speech of 1999. Mbeki's post election speech of 2004 and Zuma's post election speech of 2014 also got close to the 2500 mark.  

It's interesting that whilst the trend in the number of unique words used was most often upwards with Mandela, Mbeki and Zuma both show a mostly upward trend in the lead up to the election year, followed by a mostly downward trend after nearing the 2500 unique words mark in their post election speech.  

If we exclude the post election speeches, the number of unique words used by Mbeki during his term from 2000 to 2008 averages just under 2000 whereas the number of unique words used by Zuma during his term from 2009 to 2017 averages just over 1500.  



### **Lexical Density per President**  

Lexical density refers to the number of unique words used in each SONA divided by the total number of words and a high value is an indicator of word repitition.  

```{r density}

# word tokenization
density_per_year <- input_data$words %>%   # don't remove stop words this time
  group_by(president, year) %>% 
  summarise(density = n_distinct(word) / n()) %>% 
  arrange(desc(density))

density_per_year %>%
  ggplot(aes(x = as.numeric(year), y = density, colour = president)) +
  geom_point(color = "steelblue",
               alpha = .7,               # transparency
               size = 3,                 # point size
               position = "jitter") +    # point overlap
  geom_smooth(method = "loess", aes(colour = president)) +
  ggtitle("Lexical Density per President") +
  xlab("year") +
  ylab("")

```
  
##### **Insights:**   

De Klerk repeated over 30% of his words in his 1994 pre election SONA speech. On average, Mandela repeated about 25% of words in each of his SONA speeches and this reduced to about 20% in the post election speech of 1999. Mbeki's repitition rate was about 23% and this reduced to 20% in the post election speech of 2004. Zuma's repitition rate is over 30% with the exception of his post election speech of 2014 at about 23%.  



# **Results**


## **Sentiment Analysis**

```{r sentiment}

# audrey

```



## **Bag of Words using tf-idf**

```{r tfidf}

# merve

```



## **Topic Modelling**

```{r topic}

# vanessa

```



## **Neural Net (nn) to predict the President from a Sentence**


```{r nn}

# sam / merve??

```



### **Evaluate Out of Sample Performance**



## **Convolutional Neural Net (cnn) to predict the President from a Sentence**

```{r cnn}

# ??

```



### **Evaluate Out of Sample Performance**


#### **Recurrent Neural Net (rnn) to predict President from Sentence**


```{r rnn}

# sam

```



#### **Evaluate Out of Sample Performance**



## **Analysis of Results and Conclusion**



## **References**

https://www.kaggle.com/rtatman/tutorial-sentiment-analysis-in-r

https://www.datacamp.com/community/tutorials/sentiment-analysis-R



