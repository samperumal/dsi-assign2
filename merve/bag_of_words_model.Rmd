---
title: "Bag-of-words models"
author: "Merve Aydin Chester"
date: ""
output: 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(stringr)
library(lubridate)
library(tidytext)
library(rpart) 

```

```{r}
txt_files <- list.files("~/Downloads/sona-text-1994-2018/")

sona <- data.frame(filename = as.character(), speech = as.character())
for(i in txt_files){
  file_name <- paste0("~/Downloads/sona-text-1994-2018/", i)
  
  # import text as single character string (can also read.table but the "seperator" causes problems)
  this_speech <- readChar(file_name, 
                          nchars = file.info(file_name)$size)
  
  # make data frame with metadata (filename contains year and pres) and speech
  this_sona <- data.frame(filename = i, speech = this_speech, stringsAsFactors = FALSE)
  
  # make a single dataset
  sona <- rbind(sona, this_sona)
}

# extract year, testing
str_extract(sona$filename, "[0-9]")
str_extract_all(sona$filename, "[0-90-90-90-9]")
str_extract_all(sona$filename, "[0-9][0-9][0-9][0-9]")
str_extract_all(sona$filename, "[0-9][0-9][0-9][0-9]", simplify = T)
str_extract(sona$filename, "[0-9]{4}")

# does the same thing
str_sub(sona$filename, start = 1, end = 4)

sona$year <- str_sub(sona$filename, start = 1, end = 4)


# unnest_tokens is very useful, can split into words, sentences, lines, paragraphs, etc

# we want to predict sentences, so we need to first split into sentences
sona = sona %>% unnest_tokens(text, speech, token = "sentences")
sona$presidents = gsub(".*[_]([^.]+)[.].*", "\\1", (sona$filename))

# exercise: add an ID variable for sentences and tokenize each sentence by words

df = tibble::rowid_to_column(sona, "ID")
```



```{r}
tidy_sona = df %>% unnest_tokens(word, text, token = "words") %>% select(ID, word, filename, year, presidents) #184,038 total number of words when unnested
```

## Extracting bag-of-words data from text

```{r}
word_bag <- tidy_sona 
nrow(word_bag) #184038
```

Calculate the number of times each word was used in each of the sentences.


```{r}
sona_tdf <- tidy_sona %>%
  group_by(ID,word) %>%
  count() %>%  
  group_by(ID) %>%
  mutate(total = sum(n)) %>%
  ungroup()
```

Wide format is the format required by **rpart** change your data into wide-format.
```{r}
president_word_count = df %>%
  group_by(presidents) %>%
  unnest_tokens(word, text) %>%
  count(ID, word, sort = TRUE) %>%
  ungroup()
  
#Join to get the file name and presidents
president_word_count = left_join(president_word_count, df)

bag_of_words <- president_word_count %>% 
  select(ID, prez = presidents,  word,n) %>% 
  spread(key = word, value = n, fill = 0)

# number of sentences
nrow(bag_of_words)
# number of variables (words, plus ID and response)
ncol(bag_of_words)
```

First, many predictive modelling approaches do better with balanced data. But in this case if we use an even split we will lose quite a lot (94.53%) of data. So I will not split it.


```{r}
table(bag_of_words$prez)
```

```{r}
# min_class_size <- min(table(bag_of_words$prez))
# bag_of_words <- bag_of_words %>% group_by(prez) %>% sample_n(min_class_size) %>% ungroup()
# table(bag_of_words$prez)
```

## Building a bag-of-words classifier


```{r}

# Create train and test sets
set.seed(321)
training_ids <- bag_of_words %>% 
  group_by(prez) %>% 
  sample_frac(0.9) %>% 
  ungroup() %>%
  select(ID)

training_sona <- bag_of_words %>% 
  right_join(training_ids, by = "ID") %>%
  select(-ID)

test_sona <- bag_of_words %>% 
  anti_join(training_ids, by = "ID") %>%
  select(-ID)
```

Fit a tree to the training data.


```{r}
fit <- rpart(factor(prez) ~ ., training_sona, method = "class")
```

Plot the full tree.


```{r}
options(repr.plot.width=8, repr.plot.height=10)
plot(fit, main="Full Classification Tree")
text(fit, use.n=TRUE, all=TRUE, cex=.56)
```

Finding the accuracy of the trainin set


```{r}
fittedtrain <- predict(fit,type="class")
predtrain <- table(training_sona$prez,fittedtrain)
predtrain
sum(diag(predtrain))/sum(predtrain) # training accuracy 0.4652883
```

Finding the accuracy of the test set:

```{r}
fittedtest <- predict(fit,newdata=test_sona,type="class")
predtest <- table(test_sona$prez,fittedtest)
predtest
sum(diag(predtest))/sum(predtest) # test accuracy 0.4647696
```

## Term frequency-inverse-document-frequency (tf-idf)

**tf** is term frequency and **idf** decreases the weight of the frequently used words. So if we multiply **tf-idf** the value we find is how important a word is to a document. So using tfidf we no longer need to use redundant word dictinaries.


```{r}
ndocs <- length(unique(sona_tdf$ID)) #7364

idf <- sona_tdf %>% 
  group_by(word) %>% 
  summarize(docs_with_word = n()) %>% 
  ungroup() %>%
  mutate(idf = log(ndocs / docs_with_word)) %>% arrange(desc(idf))

sona_tdf <- sona_tdf %>% 
    left_join(idf, by = "word") %>% 
    mutate(tf = n/total, tf_idf = tf * idf)
```

Choosing a random sample sentence from the data:

```{r}
set.seed(987)
random_sona <- sample(sona_tdf$ID,1)
df %>% filter(ID == random_sona) %>% select(text)
```


```{r}
sona_tdf %>% filter(ID == random_sona) %>% arrange(desc(n))
```

The **tidytext** package has a function `bind_tf_idf()` that finds tf_idf.


```{r}
sona_tdf <- sona_tdf %>% 
    select(-idf, -tf, -tf_idf) %>% # remove the old ones we worked out
  bind_tf_idf(word, ID, n) # replace with values from tidytext

sona_tdf = sona_tdf %>% left_join(df)

sona_tdf %>% filter(ID == random_sona) %>% arrange(desc(n)) # check same as above
```

# Redoing the classification tree, this time with tf-idf features 

Tf-idf often gives better accuracy in predictive modelling than using word frequencies.

```{r}
# Spreading the data
bag_of_words <- sona_tdf %>% 
  select(ID, prez = presidents, word, tf_idf) %>%  # note the change, using tf-idf
  spread(key = word, value = tf_idf, fill = 0) %>%  
  left_join(df %>% select(ID, prez = presidents))
```

We use same training and test sets as before.

```{r}
set.seed(321)
training_ids <- bag_of_words %>% 
  group_by(prez) %>% 
  sample_frac(0.9) %>% 
  ungroup() %>%
  select(ID)

training_sona <- bag_of_words %>% 
  right_join(training_ids, by = "ID") %>%
  select(-ID)

test_sona <- bag_of_words %>% 
  anti_join(training_ids, by = "ID") %>%
  select(-ID)
```

We fit a tree to training data:


```{r}
fit <- rpart(factor(prez) ~ ., training_sona)
```

Plot the tree we just created:


```{r}
options(repr.plot.width=8, repr.plot.height=10)
plot(fit, main="Full Classification Tree")
text(fit, use.n=TRUE, all=TRUE, cex=.57)
```

And check the accuracy in training and test datasets:


```{r}
fittedtrain <- predict(fit,type="class")
predtrain <- table(training_sona$prez,fittedtrain)
predtrain
sum(diag(predtrain))/sum(predtrain) # training accuracy 0.4678539
```


```{r}
fittedtest <- predict(fit,newdata=test_sona,type="class")
predtest <- table(test_sona$prez,fittedtest)
predtest
sum(diag(predtest))/sum(predtest) # test accuracy 0.4647696
```

We get a very slight improvement in accuracy from replacing word frequency features with ones based on tf-idf.
    
